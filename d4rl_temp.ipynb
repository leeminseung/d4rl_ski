{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import gym\n",
    "import d4rl # Import required to register environments\n",
    "\n",
    "# Create the environment\n",
    "env = gym.make('halfcheetah-medium-expert-v2')\n",
    "\n",
    "# d4rl abides by the OpenAI gym interface\n",
    "env.reset()\n",
    "env.step(env.action_space.sample())\n",
    "\n",
    "# Each task is associated with a dataset\n",
    "# dataset contains observations, actions, rewards, terminals, and infos\n",
    "dataset = env.get_dataset()\n",
    "print(dataset['observations']) # An N x dim_observation Numpy array of observations\n",
    "\n",
    "# Alternatively, use d4rl.qlearning_dataset which\n",
    "# also adds next_observations.\n",
    "dataset = d4rl.qlearning_dataset(env)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Warning: Flow failed to import. Set the environment variable D4RL_SUPPRESS_IMPORT_ERROR=1 to suppress this message.\n",
      "No module named 'flow'\n",
      "/home/lms/anaconda3/envs/mujoco/lib/python3.7/site-packages/glfw/__init__.py:834: GLFWError: (65544) b'X11: The DISPLAY environment variable is missing'\n",
      "  warnings.warn(message, GLFWError)\n",
      "Warning: CARLA failed to import. Set the environment variable D4RL_SUPPRESS_IMPORT_ERROR=1 to suppress this message.\n",
      "No module named 'carla'\n",
      "/home/lms/anaconda3/envs/mujoco/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading dataset: http://rail.eecs.berkeley.edu/datasets/offline_rl/gym_mujoco_v2/halfcheetah_medium_expert-v2.hdf5 to /home/lms/.d4rl/datasets/halfcheetah_medium_expert-v2.hdf5\n",
      "[[ 1.9831914e-02 -8.9501314e-02 -3.1969063e-03 ...  1.1365079e-01\n",
      "   6.8424918e-02 -1.3811582e-01]\n",
      " [-3.8486063e-03 -5.2394319e-02  8.3050327e-03 ...  4.5068407e+00\n",
      "  -9.2885571e+00  4.7328596e+00]\n",
      " [-5.5298433e-02 -7.7850236e-05 -2.3952831e-01 ... -7.0811687e+00\n",
      "  -1.4037068e+00  7.5524049e+00]\n",
      " ...\n",
      " [-3.8276739e-02 -5.9685200e-03 -5.3859454e-01 ...  9.6563587e+00\n",
      "  -9.2510633e+00 -2.3956337e+00]\n",
      " [-3.5350587e-02 -1.3052115e-01 -1.6677204e-01 ... -3.3741906e+00\n",
      "  -4.8845510e+00 -5.1081996e+00]\n",
      " [-9.0780985e-03 -1.5547317e-01  6.0090959e-01 ... -2.2751564e+01\n",
      "  -3.7737691e+00 -3.9162564e+00]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "dataset.keys()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_keys(['observations', 'actions', 'next_observations', 'rewards', 'terminals'])"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "dataset['observations'].shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1998000, 17)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import torch.nn as nn"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "source": [
    "class BigEncoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(BigEncoder, self).__init__()\n",
    "         \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, output_size)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "class StochasticTransitionModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, minimum_std = 0.001):\n",
    "        super(StochasticTransitionModel, self).__init__()\n",
    "\n",
    "        self.make_prob_parameters = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 2 * output_size)\n",
    "        )\n",
    "\n",
    "        self.minimum_std = minimum_std\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        flatted_mu_std = self.make_prob_parameters(x)\n",
    "        reshaped_mu_std = flatted_mu_std.reshape(-1, self.output_size, 2)\n",
    "        mu = reshaped_mu_std[:, :, 0]\n",
    "        std = reshaped_mu_std[:, :, 1]\n",
    "\n",
    "        std += self.minimum_std\n",
    "        epsilon = torch.randn((x.shape[0], self.output_size))\n",
    "        next_state_prediction = epsilon * std + mu\n",
    "        return next_state_prediction"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "import random\n",
    "import torch \n",
    "\n",
    "class EntireEnsembleModel(nn.Module):\n",
    "    def __init__(self, input_size, encoder_hidden_size, encoder_output_size, transition_model_hidden_size, transition_model_output_size, ensemble_size, learning_rate):\n",
    "        super(EntireEnsembleModel, self).__init__()\n",
    "        \n",
    "        self.ensemble_size = ensemble_size\n",
    "        self.big_encoder = BigEncoder(input_size, encoder_hidden_size, encoder_output_size)\n",
    "        self.stochastic_models = list()\n",
    "        for _ in range(ensemble_size):\n",
    "            self.stochastic_models.append(StochasticTransitionModel(encoder_hidden_size, transition_model_hidden_size, transition_model_output_size))\n",
    "        \n",
    "        self.all_parameters = list(self.big_encoder.parameters())\n",
    "        for idx in range(ensemble_size):\n",
    "            self.all_parameters += list(self.stochastic_models[idx].parameters())\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.all_parameters, lr=learning_rate)\n",
    "\n",
    "    def forward(self, state, action):\n",
    "        state_action = torch.cat((state, action), dim=1)\n",
    "        latent = self.big_encoder(state_action)\n",
    "        selected_model_idx = random.choice(range(len(self.stochastic_models)))\n",
    "        selected_model =self.stochastic_models[selected_model_idx]\n",
    "        next_state_prediction = selected_model(latent)\n",
    "        return next_state_prediction\n",
    "        \n",
    "        \n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class D4rlDataset(nn.Module):\n",
    "    def __init__(self, d4rl_dataset):\n",
    "        super(D4rlDataset, self).__init__()\n",
    "        self.d4rl_dataset = d4rl_dataset\n",
    "        self.state_array = d4rl_dataset['observations']\n",
    "        self.next_state_array = d4rl_dataset['next_observations']\n",
    "        self.action_array = d4rl_dataset['actions']\n",
    "        self.reward_array = d4rl_dataset['rewards']\n",
    "        self.terminal_array = d4rl_dataset['terminals']        \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {'state': self.state_array[idx], 'action': self.action_array[idx], 'next_state': self.next_state_array[idx]}\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.state_array.shape[0]\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1998000, 17)"
      ]
     },
     "metadata": {},
     "execution_count": 82
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "whole_ind = np.arange(dataset['observations'].shape[0])\n",
    "train_ind, val_ind = train_test_split(whole_ind, test_size=0.1, random_state = 42)\n",
    "train_ind, test_ind = train_test_split(train_ind, test_size=0.1, random_state = 42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "source": [
    "train_dataset = {}\n",
    "val_dataset = {}\n",
    "test_dataset = {}\n",
    "\n",
    "for key in dataset.keys():\n",
    "    train_dataset[key] = dataset[key][train_ind]\n",
    "    val_dataset[key] = dataset[key][val_ind]\n",
    "    test_dataset[key] = dataset[key][test_ind]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "source": [
    "d4rl_train_dataset = D4rlDataset(dataset)\n",
    "d4rl_train_dataloader = DataLoader(d4rl_train_dataset, batch_size=256, shuffle=True, drop_last=False)\n",
    "\n",
    "d4rl_val_dataset = D4rlDataset(dataset)\n",
    "d4rl_val_dataloader = DataLoader(d4rl_val_dataset, batch_size=256, shuffle=True, drop_last=False)\n",
    "\n",
    "d4rl_test_dataset = D4rlDataset(dataset)\n",
    "d4rl_test_dataloader = DataLoader(d4rl_test_dataset, batch_size=256, shuffle=True, drop_last=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "source": [
    "model = EntireEnsembleModel(input_size=17+6, encoder_hidden_size=64, encoder_output_size=64, transition_model_hidden_size=64, transition_model_output_size=17, ensemble_size=5, learning_rate=0.0005)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss_sum = 0\n",
    "    for row in d4rl_train_dataloader:\n",
    "        state = row['state']\n",
    "        action = row['action']\n",
    "        next_state = row['next_state']\n",
    "\n",
    "        next_state_prediction = model(state, action)\n",
    "        loss = loss_fn(next_state, next_state_prediction)\n",
    "\n",
    "        loss.backward()\n",
    "        model.optimizer.step()\n",
    "        model.optimizer.zero_grad()\n",
    "\n",
    "        loss_sum += loss.item()\n",
    "\n",
    "    print('Train Mean Loss at {} epoch: {}'.format(loss_sum/len(d4rl_train_dataloader), epoch))\n",
    "\n",
    "    loss_sum = 0\n",
    "    with torch.no_grad():\n",
    "        for row in d4rl_val_dataloader:\n",
    "            state = row['state']\n",
    "            action = row['action']\n",
    "            next_state = row['next_state']\n",
    "\n",
    "            next_state_prediction = model(state, action)\n",
    "            loss = loss_fn(next_state, next_state_prediction)\n",
    "\n",
    "            loss_sum += loss.item()\n",
    "\n",
    "    print('Validation Mean Loss at {} epoch: {}'.format(loss_sum/len(d4rl_train_dataloader), epoch))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "print('observation size:', dataset['observations'].shape)\n",
    "print('action size:', dataset['actions'].shape)\n",
    "print('next observation size:', dataset['next_observations'].shape)\n",
    "print('rewards size:', dataset['rewards'].shape)\n",
    "print('terminal size:', dataset['terminals'].shape)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "observation size: (1998000, 17)\n",
      "action size: (1998000, 6)\n",
      "next observation size: (1998000, 17)\n",
      "rewards size: (1998000,)\n",
      "terminal size: (1998000,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('mujoco': conda)"
  },
  "interpreter": {
   "hash": "9ee2970a14e6a8f72b339ef15f848f36d69c3eb504f2e44ffee4c94d188b3a88"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}